Main Method = The entry point of a Java program

public static void main(String[] args) {
        *CODE*
}

public = Needs to be public so that the JRE (Java Runtime Environment) can access and execute it.
static = Needs to be static so that the JVM can load the class into memory and call the main method without creating an instance of the class first.
void = Return type is void because the main function shouldn't return anything, when it finishes executing, the Java program simply terminates.
String[] args = accepts arguments from the command line that are stored in a String array to affect the operation of the program.


Algorithm = A collection of steps to solve a problem
Ex: Linear Search = Examining the elements of an array one by one to find a value.

----------------------DATA STRUCTURES-------------------------------------------------------------------------------------------------------
Data Structures = Named location used to store and organize data
Ex: Array = A collection of elements stores in contiguous memory locations.

STACK
LIFO data structure (Last in first out).
Stores objects as a "vertical tower", like a stack of books or cds.
push() method is used to add objects to the top.
pop() method is used to remove from the top.

QUEUE
FIFO data structure (First in first out)
A collection designed for holding elements prior to processing.
Linear data structure (a data structure that stores data sequentially)
Head = First element of the queue
Tail = Last element of the queue
enqueue = adding an object to the end of the queue
dequeue = removing an object from the head of the queue

PRIORITY QUEUE
A FIFO data structure that serves elements with the highest priority first before elements with lower priority
Its like a normal queue, but you sort the elements first based on a parameter, so you can serve the elements
with the highest priority first and work your way down to the lowest priority.

LINKED LISTS
Stores nodes in 2 parts (data + address)
Nodes are in non-consecutive memory locations, elements are linked using pointers

Singly LinkedList structure (Address points only to the next node)
     Node                 Node                Node
[data | address] ->  [data | address] -> [data | address]

Doubly LinkedList structure (Address points to the previous and next node)
           Node                            Node
[address | data | address] <->  [address | data | address]

Advantages:
1 - Dynamic Data Structure (allocates needed memory while running)
2 - Insertion and Deletion of Nodes is easy, 0(1) constant time complexity
3 - No/Low Memory Waste

Disadvantages:
1 - Greater memory usage(additional pointer for the address, even more so with a doubly linked list)
2 - No random access of elements (no index[i])
3 - Accessing/searching elements is more time-consuming 0(n) linear time complexity

Use examples:
1 - Implement Stacks and Queues
2 - GPS navigation
(If you have a starting position and a final destination, every stop along the way can be seen as a node,
 and changing the path is as simple as changing, inserting or deleting a node)
3 - Music Playlists

DYNAMIC ARRAYS

Static Array = new String[capacity];
Can access elements directly with 0(1) constant time, but searching takes more time the larger the amount of elements, O(n) linear time complexity.
Has a fixed capacity of elements.

Dynamic arrays have their own static array with a fixed size, but once its inner static array reaches capacity, a dynamic array will instantiate
a new array with an increased capacity, copying the elements over to the new array

Advantages:
1 - Random memory access
2 - Good data cache utilization due to contiguous memory addresses
3 - Easy to insert/delete at tail due to no shifting of elements

Disadvantages:
1 - Memory wastage compared to LinkedLists due to increases in array capacity to accommodate more elements not being the exact number of new elements
leading to null memory addresses
2 - Shifting of elements has O(n) linear time complexity due to all elements needing to be shifted to the left in case of a deletion, or to the right
in case of an insertion.
3 - Expanding/Shrinking the array has 0 (n) linear time complexity due to needing to copy all the elements over to a new array with a new capacity

Big O notation:
"How code slows as data grows"
1 - Describes the performance of an algorithm as the amount of data increases
2 - Machine independent, it focuses on the number of steps to complete an algorithm, independent of hardware.
3 - Ignores smaller operations Ex: O(n + 1) -> 0(n), the +1 wouldn't make much of a difference.

Examples of notations:
n = A variable for the amount of data.

O(1) = Constant time, takes the same amount of time regardless of data.
O(log n) = Logarithmic time, becomes more efficient the larger the amount of data.
O(n) = Linear time, increases time proportionally to the amount of data
0(n log n) = Quasilinear time, it's similar to linear time for the most part, but gets less and less efficient the larger the dataset.
O(n^2) = Quadratic time, becomes much less efficient the larger the amount of data.
0(n!) = Factorial time, gets extremely less efficient the larger the amount of data.

----------------------SORTING ALGORITHMS-------------------------------------------------------------------------------------------------------

BUBBLE SORT
Pairs of adjacent elements are compared, and the elements are swapped if they aren't in order
Its slow as hell, but very simple, so it's mostly used for educational purposes as an introduction to sorting algorithms.
In small data sets its passable but starts becoming extremely inefficient the larger the data set becomes.
Time Complexity = 0(n^2)

SELECTION SORT
Search through an array and keep track of the minimum value during each iteration, at the end of each iteration, we swap variables.
It's a bit more efficient than bubble sort, since it does fewer swaps per iteration.
Still, it becomes increasingly less efficient as the data set grows, used mostly for educational purposes.
Time complexity = 0(n^2)

INSERTION SORT
Starting from index 1, put the element on a temporary variable (temp)
compare the elements to the left and shift elements to the right if they are larger than what is in temp
Then put the temp element on the opening left after shifting the elements to the right.
Time complexity = O(n^2), though it can also run at 0(n) in the best case scenario where all the elements are already sorted.
Fewer steps than bubble sort, and runs in O(n) if the elements are already sorted.










----------------------SEARCH ALGORITHMS-------------------------------------------------------------------------------------------------------

LINEAR SEARCH

Linear search = iterate through a collection one element at a time
Time complexity = O(n)

Advantages:
Fast for searches in small to medium data sets
Doesn't need to be sorted
Useful for data structures that don't have random access, like LinkedLists

Disadvantages:
Slow for large data sets

BINARY SEARCH

Binary search = finds the position of a target value within a sorted array, half of the array is eliminated during each "step".
Time complexity = 0(log n)

Advantages:
Gets more efficient the higher the amount of data

Disadvantages:
Dataset has to be sorted beforehand
Can be slower than linear search in small datasets

INTERPOLATION SEARCH

Interpolation search = Improvement over binary searches used for uniformly distributed data
It "guesses" where a value might be based on calculated probe results, if the probe is incorrect,
search area is narrowed and a new probe is calculated.

It basically guesses where the value is and returns the index

Time complexity:
Average case: O(log(log(n))
Worst case: O(n) values increase exponentially





